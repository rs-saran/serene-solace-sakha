{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pytz\n",
    "from IPython.display import Image, display\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "# from langchain.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import ToolException\n",
    "\n",
    "@tool\n",
    "def SetReminderTool(activity_name: str, start_time_hour:int, start_time_minutes: int, duration:int, run_manager: Optional[CallbackManagerForToolRun] = None, \n",
    "    ) -> str:\n",
    "        \"\"\"useful for when you need to set a reminder. Do not set a reminder until user agrees on an activity , time and duration \"\"\"\n",
    "        return f\"Reminder set for {activity_name} for {start_time_hour}hrs {start_time_minutes}mins for a duration of {duration} minutes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            # _printed.add(message.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langchain_core.messages import AnyMessage\n",
    "from response_templates.supervisor_response import SupervisorResponse\n",
    "\n",
    "# Conversation State to hold all user interaction details\n",
    "class ConversationState(TypedDict):\n",
    "    exchange: int\n",
    "    conversation_history: list[AnyMessage]\n",
    "    preferred_activities: list[str]\n",
    "    user_input: str\n",
    "    supervisor_response: SupervisorResponse\n",
    "    flow: str\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "\n",
    "# class Frienn:\n",
    "#     def __init__(self, runnable: Runnable):\n",
    "#         self.runnable = runnable\n",
    "\n",
    "#     def __call__(self, state: ConversationState, config: RunnableConfig):\n",
    "#         while True:\n",
    "#             configuration = config.get(\"configurable\", {})\n",
    "#             passenger_id = configuration.get(\"passenger_id\", None)\n",
    "#             state = {**state, \"user_info\": passenger_id}\n",
    "#             result = self.runnable.invoke(state)\n",
    "            \n",
    "#             if not result.tool_calls and (\n",
    "#                 not result.content\n",
    "#                 or isinstance(result.content, list)\n",
    "#                 and not result.content[0].get(\"text\")\n",
    "#             ):\n",
    "#                 messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "#                 state = {**state, \"messages\": messages}\n",
    "#             else:\n",
    "#                 break\n",
    "#         return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'State' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mlanggraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m END, StateGraph, START\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mlanggraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprebuilt\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tools_condition\n\u001b[1;32m----> 5\u001b[0m builder \u001b[39m=\u001b[39m StateGraph(State)\n\u001b[0;32m      8\u001b[0m \u001b[39m# # Define nodes: these do the work\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# builder.add_node(\"assistant\", Assistant(part_1_assistant_runnable))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# builder.add_node(\"tools\", create_tool_node_with_fallback(part_1_tools))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m#     # This requires some extra dependencies and is optional\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m#     pass\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'State' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# # Define nodes: these do the work\n",
    "# builder.add_node(\"assistant\", Assistant(part_1_assistant_runnable))\n",
    "# builder.add_node(\"tools\", create_tool_node_with_fallback(part_1_tools))\n",
    "# # Define edges: these determine how the control flow moves\n",
    "# builder.add_edge(START, \"assistant\")\n",
    "# builder.add_conditional_edges(\n",
    "#     \"assistant\",\n",
    "#     tools_condition,\n",
    "# )\n",
    "# builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# # The checkpointer lets the graph persist its state\n",
    "# # this is a complete memory for the entire graph.\n",
    "# memory = MemorySaver()\n",
    "# part_1_graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "# try:\n",
    "#     display(Image(part_1_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "# except Exception:\n",
    "#     # This requires some extra dependencies and is optional\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from response_templates.conversation_state import ConversationState\n",
    "from utils import exchanges_pretty, get_current_time_ist, fetch_user_preferences, get_current_time_ist_30min_lag\n",
    "\n",
    "class ChatEngine:\n",
    "    def __init__(self, llm:Runnable):\n",
    "        self.llm = llm\n",
    "        self.bot_char_prompt = self.get_frienn_char_prompt()\n",
    "        self.conversation_history = []\n",
    "        self.exchange = 0\n",
    "        self.flow = \"activity_suggestion\"\n",
    "\n",
    "    def get_frienn_char_prompt(self):\n",
    "        \n",
    "        base_char_prompt = f'''You are Frienn, a kind and empathetic virtual companion designed by Friendly, designed to suggest activities to improve users mood and follow up on the activities.\n",
    "\n",
    "        Behavior Guidelines:\n",
    "\n",
    "        Be empathetic, respectful, and friendly.\n",
    "        Respond with brief, short and clear sentences.\n",
    "        If the user is felling low offering thoughtful suggestions or encouragement if not just chat like a friend\n",
    "        Never provide medical, legal, or financial advice.\n",
    "\n",
    "        '''\n",
    "\n",
    "        return base_char_prompt\n",
    "\n",
    "    def get_activity_suggestion_guidelines(self):\n",
    "\n",
    "        return '''Activity Suggestion Guidelines:\n",
    "\n",
    "                1. Prioritize the user's preferred activities; otherwise, suggest a suitable one.\n",
    "                2. Avoid digital engagement activities or games.\n",
    "                3. Consider the user's time and location when suggesting activities, including appropriate duration.\n",
    "                4. Ask if they want to do it now or later, rounding the suggested time.\n",
    "                5. Keep choices and questions minimal to avoid overwhelming the user.\n",
    "                6. Confirm the activity and time before finalizing.\n",
    "                7. If not immediate, set a reminder using below command in the response:\n",
    "                    <set_reminder> {chosen_activity} at {start_time} until {end_time}</set_reminder>\n",
    "                    if multiple repeat the above line for each activity and time combination\n",
    "                8. After setting the reminder, try to end the conversation.\n",
    "\n",
    "                '''\n",
    "                \n",
    "    def get_reminder_details(self):\n",
    "        return f'''Walking at {get_current_time_ist()}'''\n",
    "\n",
    "\n",
    "\n",
    "    def generate_response(self, user_input, preferred_activities):\n",
    "\n",
    "        conversation_history_pretty = exchanges_pretty(self.conversation_history)\n",
    "        print(\"You:\", user_input)\n",
    "        \n",
    "        if self.flow == \"activity_suggestion\":\n",
    "            if self.exchange == 0:\n",
    "                chat_prompt_msgs = [\n",
    "                    SystemMessage(self.get_frienn_char_prompt()),\n",
    "                    SystemMessage(self.get_activity_suggestion_guidelines()),\n",
    "                    SystemMessage(\"Introduce yourself briefly and naturally before suggesting an activity\"),\n",
    "                    HumanMessage(user_input)\n",
    "                     ]\n",
    "            else: \n",
    "                chat_prompt_msgs = [\n",
    "                SystemMessage(self.get_frienn_char_prompt()),\n",
    "                SystemMessage(self.get_activity_suggestion_guidelines()),\n",
    "                SystemMessage(f\"Activities preferred by user: {preferred_activities}\"),\n",
    "                SystemMessage(f\"Current time: {get_current_time_ist()}\"),\n",
    "                SystemMessage(f\"Conversation History:<conversation_history>{conversation_history_pretty}</conversation_history>\"),\n",
    "                HumanMessage(user_input)\n",
    "                            ]\n",
    "\n",
    "        elif self.flow == \"reminder\":\n",
    "            if self.exchange == 0:\n",
    "                chat_prompt_msgs = [\n",
    "                    SystemMessage(self.bot_char_prompt),\n",
    "                    SystemMessage(f\"Current time: {get_current_time_ist()}\"),\n",
    "                    SystemMessage(f\"Conversation History:<conversation_history>{conversation_history_pretty}</conversation_history>\"),\n",
    "                    SystemMessage(f\"Previously you set a reminder for {self.get_reminder_details()}. It’s time! Encourage the user to start their activity with enthusiasm and motivation.\"),\n",
    "                ]\n",
    "            else:\n",
    "                chat_prompt_msgs = [\n",
    "                    SystemMessage(self.bot_char_prompt),\n",
    "                    SystemMessage(f\"Current time: {get_current_time_ist()}\"),\n",
    "                    SystemMessage(f\"Conversation History:<conversation_history>{conversation_history_pretty}</conversation_history>\"),\n",
    "                    SystemMessage(f\"Reminder details: {self.get_reminder_details()}. Motivate the user to complete the activity. If they seem reluctant, suggest small fun modifications to make it more enjoyable else end the conversation.\"),\n",
    "                    HumanMessage(user_input)\n",
    "                ]\n",
    "\n",
    "        elif self.flow == \"follow-up\":\n",
    "            if self.exchange == 0:\n",
    "                chat_prompt_msgs = [\n",
    "                    SystemMessage(self.bot_char_prompt),\n",
    "                    SystemMessage(f\"Activities preferred by user: {preferred_activities}\"),\n",
    "                    SystemMessage(f\"Current time: {get_current_time_ist()}\"),\n",
    "                    SystemMessage(f\"Conversation History:<conversation_history>{conversation_history_pretty}</conversation_history>\"),\n",
    "                    SystemMessage(f\"You set a reminder for walking at {get_current_time_ist_30min_lag()}. Check in on the user’s experience—ask if they completed it and how it made them feel.\"),\n",
    "                ]\n",
    "            else:\n",
    "                chat_prompt_msgs = [\n",
    "                    SystemMessage(self.bot_char_prompt),\n",
    "                    SystemMessage(f\"Activities preferred by user: {preferred_activities}\"),\n",
    "                    SystemMessage(f\"Current time: {get_current_time_ist()}\"),\n",
    "                    SystemMessage(f\"Previously you have set a reminder for walking at {get_current_time_ist_30min_lag()}. Now you are checking in on the user. Continue the conversation as friend and end the conversation. Do not suggest more activities if user is feeling better.\"),\n",
    "                    SystemMessage(f\"Conversation History:<conversation_history>{conversation_history_pretty}</conversation_history>\"),\n",
    "                    HumanMessage(user_input)\n",
    "                ]\n",
    "\n",
    "\n",
    "        else:\n",
    "            \n",
    "            chat_prompt_msgs = [\n",
    "                SystemMessage(self.bot_char_prompt),\n",
    "                SystemMessage(f\"Activities preferred by user: {preferred_activities}\"),\n",
    "                SystemMessage(f\"Current time: {get_current_time_ist()}\"),\n",
    "                SystemMessage(f\"Conversation History:<conversation_history>{conversation_history_pretty}</conversation_history>\"),\n",
    "                HumanMessage(user_input)\n",
    "            ]\n",
    "\n",
    "        \n",
    "        model_response = self.llm.invoke(chat_prompt_msgs)\n",
    "        print(f\"Frienn :\", model_response.content)\n",
    "        self.messages.append(model_response)\n",
    "        \n",
    "        self.update_conversation_history(user_input, model_response.content)\n",
    "        self.exchange += 1\n",
    "        \n",
    "    def update_conversation_history(self, user_input, response):\n",
    "        self.conversation_history.append(HumanMessage(content=user_input))\n",
    "        self.conversation_history.append(AIMessage(content=response))\n",
    "\n",
    "    def __call__(self,  conversation_state:ConversationState):\n",
    "        user_input = conversation_state[\"user_input\"]\n",
    "        preferred_activities = conversation_state.get(\"preferred_activities\", [\"no preferences provided\"])\n",
    "        self.conversation_history = conversation_state.get(\"conversation_history\", [])\n",
    "        self.messages = conversation_state.get(\"messages\", [])\n",
    "        self.exchange = conversation_state.get(\"exchange\", 0)\n",
    "        self.flow =  conversation_state.get(\"flow\", \"activity_suggestion\")\n",
    "        \n",
    "        self.generate_response(user_input, preferred_activities)\n",
    "        \n",
    "        return {\n",
    "            \"conversation_history\": self.conversation_history,\n",
    "            \"user_input\": user_input,\n",
    "            \"exchange\": self.exchange,\n",
    "            \"messages\": self.messages\n",
    "        }\n",
    "\n",
    "    # def __call__(self, state: ConversationState, config: RunnableConfig):\n",
    "    #     while True:\n",
    "    #         configuration = config.get(\"configurable\", {})\n",
    "    #         passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    #         state = {**state, \"user_info\": passenger_id}\n",
    "    #         result = self.runnable.invoke(state)\n",
    "            \n",
    "    #         if not result.tool_calls and (\n",
    "    #             not result.content\n",
    "    #             or isinstance(result.content, list)\n",
    "    #             and not result.content[0].get(\"text\")\n",
    "    #         ):\n",
    "    #             messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "    #             state = {**state, \"messages\": messages}\n",
    "    #         else:\n",
    "    #             break\n",
    "    #     return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Assuming these are defined elsewhere in your project\n",
    "from supervisor import Supervisor\n",
    "# from chat_engine import ChatEngine\n",
    "from reminder_manager import set_activity_reminder\n",
    "from crisis_handler import crisis_handler\n",
    "from response_templates.supervisor_response import SupervisorResponse\n",
    "from response_templates.conversation_state import ConversationState\n",
    "\n",
    "# Graph Builder Class to manage the state graph and routing\n",
    "class ConversationGraph:\n",
    "    def __init__(self,llm_sv, llm_f, frienn_tools):\n",
    "        self.llm_sv = llm_sv\n",
    "        self.llm_f = llm_f\n",
    "        self.frienn_tools = frienn_tools\n",
    "        self.builder = StateGraph(ConversationState)\n",
    "        self._add_nodes()\n",
    "        self._add_edges()\n",
    "        \n",
    "\n",
    "\n",
    "    def _add_nodes(self):\n",
    "        \"\"\"Add all nodes to the graph\"\"\"\n",
    "        self.builder.add_node(\"Supervisor\", Supervisor(llm=self.llm_sv).get_supervisor_decision)\n",
    "        self.builder.add_node(\"Frienn\", ChatEngine(llm=self.llm_f))\n",
    "        self.builder.add_node(\"crisisHandler\", crisis_handler)\n",
    "        self.builder.add_node(\"frienn_tools\", create_tool_node_with_fallback(self.frienn_tools))\n",
    "\n",
    "    def _add_edges(self):\n",
    "        \"\"\"Define and add edges to the graph\"\"\"\n",
    "        self.builder.add_edge(START, \"Supervisor\")\n",
    "        self.builder.add_conditional_edges(\"Supervisor\", self._determine_route)\n",
    "        self.builder.add_conditional_edges(\"Frienn\",tools_condition,{\n",
    "        # If it returns 'action', route to the 'tools' node\n",
    "        \"action\": \"frienn_tools\",\n",
    "        # If it returns '__end__', route to the end\n",
    "        \"__end__\": \"__end__\",\n",
    "    },)\n",
    "        self.builder.add_edge(\"Frienn\", END)\n",
    "        self.builder.add_edge(\"crisisHandler\", END)\n",
    "        \n",
    "\n",
    "    def _determine_route(self, conversation_state: ConversationState) -> Literal[\"Frienn\", \"crisisHandler\"]:\n",
    "        \"\"\"Determine the next route based on the supervisor response\"\"\"\n",
    "        supervisor_response = conversation_state.get(\"supervisor_response\")\n",
    "        picked_route = supervisor_response.pickedRoute\n",
    "\n",
    "        if picked_route == 'continue_chat':\n",
    "            return \"Frienn\"\n",
    "        elif picked_route == 'crisis_helpline':\n",
    "            return \"crisisHandler\"\n",
    "        # elif picked_route == 'set_reminder':\n",
    "        #     return \"setReminder\"\n",
    "        else:\n",
    "            return \"Frienn\"\n",
    "\n",
    "    def compile(self):\n",
    "        \"\"\"Compile the final state graph with memory saver\"\"\"\n",
    "        memory = MemorySaver()\n",
    "        return self.builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_llm\n",
    "llm_sv = get_llm()\n",
    "llm_f = get_llm().bind_tools([SetReminderTool])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_graph = ConversationGraph(llm_sv, llm_f, frienn_tools=[SetReminderTool]).compile()\n",
    "# processor = ConversationProcessor(conversation_graph)\n",
    "cs2 = conversation_graph.update_state(config={'configurable':{'thread_id':\"1\", 'user_id':\"dev-user\"}}, values = {'preferred_activities': [ 'walking'], 'flow':'activity_suggestion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Supervisor Decision: pickedRoute='continue_chat' reason='initial greeting, no indication of crisis' <=====\n",
      "You: hi\n",
      "Frienn : I'm Frienn, nice to meet you. How are you feeling today? Would you like to do something to brighten up your day? Maybe go for a walk or do some stretching?\n"
     ]
    }
   ],
   "source": [
    "tutorial_questions = [\"hi\"]\n",
    "config = {\"configurable\": {\"thread_id\": 12, \"user_id\": 'user_id'}}\n",
    "\n",
    "_printed = set()\n",
    "for question in tutorial_questions:\n",
    "    events = conversation_graph.stream(\n",
    "        {\"user_input\": question}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "\n",
    "# user_input = \"hi\"\n",
    "# config = {\"configurable\": {\"thread_id\": 121, \"user_id\": 'user_id'}}\n",
    "# conversation_graph.invoke({\"user_input\": user_input}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in events:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_questions = [\"good\"]\n",
    "config = {\"configurable\": {\"thread_id\": 0, \"user_id\": 'user_id'}}\n",
    "\n",
    "_printed = set()\n",
    "for question in tutorial_questions:\n",
    "    events = conversation_graph.stream(\n",
    "        {\"user_input\": question}, config, stream_mode=\"debug\"\n",
    "    )\n",
    "    # for event in events:\n",
    "    #     _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Supervisor Decision: pickedRoute='continue_chat' reason='user is interested in going for a walk and has agreed on a time, no indication of crisis or harmful intentions' <=====\n",
      "You: sounds interesting, 8 works\n",
      "Frienn : \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m question \u001b[39min\u001b[39;00m tutorial_questions:\n\u001b[0;32m      6\u001b[0m     events \u001b[39m=\u001b[39m conversation_graph\u001b[39m.\u001b[39mstream(\n\u001b[0;32m      7\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39muser_input\u001b[39m\u001b[39m\"\u001b[39m: question}, config, stream_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     )\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mfor\u001b[39;49;00m event \u001b[39min\u001b[39;49;00m events:\n\u001b[0;32m     10\u001b[0m         _print_event(event, _printed)\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[39m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m     \u001b[39m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m     \u001b[39m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m     \u001b[39m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[39m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[39mwhile\u001b[39;00m loop\u001b[39m.\u001b[39mtick(input_keys\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_channels):\n\u001b[1;32m-> 1670\u001b[0m         \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m runner\u001b[39m.\u001b[39;49mtick(\n\u001b[0;32m   1671\u001b[0m             loop\u001b[39m.\u001b[39;49mtasks\u001b[39m.\u001b[39;49mvalues(),\n\u001b[0;32m   1672\u001b[0m             timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_timeout,\n\u001b[0;32m   1673\u001b[0m             retry_policy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretry_policy,\n\u001b[0;32m   1674\u001b[0m             get_waiter\u001b[39m=\u001b[39;49mget_waiter,\n\u001b[0;32m   1675\u001b[0m         ):\n\u001b[0;32m   1676\u001b[0m             \u001b[39m# emit output\u001b[39;49;00m\n\u001b[0;32m   1677\u001b[0m             \u001b[39myield from\u001b[39;49;00m output()\n\u001b[0;32m   1678\u001b[0m \u001b[39m# emit output\u001b[39;00m\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\pregel\\runner.py:231\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    229\u001b[0m t \u001b[39m=\u001b[39m tasks[\u001b[39m0\u001b[39m]\n\u001b[0;32m    230\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m     run_with_retry(\n\u001b[0;32m    232\u001b[0m         t,\n\u001b[0;32m    233\u001b[0m         retry_policy,\n\u001b[0;32m    234\u001b[0m         configurable\u001b[39m=\u001b[39;49m{\n\u001b[0;32m    235\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[0;32m    236\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[0;32m    237\u001b[0m         },\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommit(t, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    240\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[39m.\u001b[39mwrites\u001b[39m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[39m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m task\u001b[39m.\u001b[39;49mproc\u001b[39m.\u001b[39;49minvoke(task\u001b[39m.\u001b[39;49minput, config)\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m ParentCommand \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:464\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    463\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m, config)\n\u001b[0;32m    465\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     context\u001b[39m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 226\u001b[0m     ret \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, Runnable) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurse:\n\u001b[0;32m    228\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\graph\\graph.py:96\u001b[0m, in \u001b[0;36mBranch._route\u001b[1;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[0;32m     94\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m     95\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minvoke(value, config)\n\u001b[1;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_finish(writer, \u001b[39minput\u001b[39;49m, result, config)\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\graph\\graph.py:132\u001b[0m, in \u001b[0;36mBranch._finish\u001b[1;34m(self, writer, input, result, config)\u001b[0m\n\u001b[0;32m    129\u001b[0m     result \u001b[39m=\u001b[39m [result]\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mends:\n\u001b[0;32m    131\u001b[0m     destinations: Sequence[Union[Send, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 132\u001b[0m         r \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(r, Send) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mends[r] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m result\n\u001b[0;32m    133\u001b[0m     ]\n\u001b[0;32m    134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     destinations \u001b[39m=\u001b[39m cast(Sequence[Union[Send, \u001b[39mstr\u001b[39m]], result)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tools'",
      "\u001b[0mDuring task with name 'Frienn' and id '636563a0-b965-9a29-4f8c-65d44a9498ef'"
     ]
    }
   ],
   "source": [
    "tutorial_questions = [\"sounds interesting, 8 works\"]\n",
    "config = {\"configurable\": {\"thread_id\": 0, \"user_id\": 'user_id'}}\n",
    "\n",
    "_printed = set()\n",
    "for question in tutorial_questions:\n",
    "    events = conversation_graph.stream(\n",
    "        {\"user_input\": question}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Supervisor Decision: pickedRoute='continue_chat' reason='user just started the conversation with a greeting and no indication of crisis or harmful intentions' <=====\n",
      "You: hi\n",
      "Frienn : I'm Frienn, nice to meet you. How's your day going so far? Want to do something fun?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exchange': 2,\n",
       " 'conversation_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm Frienn, nice to meet you. How's your day going so far? Want to do something fun?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm Frienn, nice to meet you. How's your day going so far? Want to do something fun?\", additional_kwargs={}, response_metadata={})],\n",
       " 'user_input': 'hi',\n",
       " 'supervisor_response': SupervisorResponse(pickedRoute='continue_chat', reason='user just started the conversation with a greeting and no indication of crisis or harmful intentions')}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"hi\"\n",
    "config = {\"configurable\": {\"thread_id\": 121, \"user_id\": 'user_id'}}\n",
    "conversation_graph.invoke({\"user_input\": user_input}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Supervisor Decision: pickedRoute='continue_chat' reason='user responded with a positive sentiment' <=====\n",
      "You: good\n",
      "Frienn : That's great to hear. Would you like to go for a walk or do some stretching exercises? We could do it now or later, say around 8:00 AM?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exchange': 3,\n",
       " 'conversation_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm Frienn, nice to meet you. How's your day going so far? Want to do something fun?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm Frienn, nice to meet you. How's your day going so far? Want to do something fun?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='good', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's great to hear. Would you like to go for a walk or do some stretching exercises? We could do it now or later, say around 8:00 AM?\", additional_kwargs={}, response_metadata={})],\n",
       " 'user_input': 'good',\n",
       " 'supervisor_response': SupervisorResponse(pickedRoute='continue_chat', reason='user responded with a positive sentiment')}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"good\"\n",
    "config = {\"configurable\": {\"thread_id\": 121, \"user_id\": 'user_id'}}\n",
    "conversation_graph.invoke({\"user_input\": user_input}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Supervisor Decision: pickedRoute='continue_chat' reason=\"User's input 'ok' indicates a neutral or positive response, and there's no indication of harmful intentions or suicidal tendencies.\" <=====\n",
      "You: ok\n",
      "Frienn : \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m user_input \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mok\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m config \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mconfigurable\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mthread_id\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m121\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m}}\n\u001b[1;32m----> 3\u001b[0m conversation_graph\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39muser_input\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_input}, config)\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1961\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1959\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1960\u001b[0m     chunks \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 1961\u001b[0m \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream(\n\u001b[0;32m   1962\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   1963\u001b[0m     config,\n\u001b[0;32m   1964\u001b[0m     stream_mode\u001b[39m=\u001b[39;49mstream_mode,\n\u001b[0;32m   1965\u001b[0m     output_keys\u001b[39m=\u001b[39;49moutput_keys,\n\u001b[0;32m   1966\u001b[0m     interrupt_before\u001b[39m=\u001b[39;49minterrupt_before,\n\u001b[0;32m   1967\u001b[0m     interrupt_after\u001b[39m=\u001b[39;49minterrupt_after,\n\u001b[0;32m   1968\u001b[0m     debug\u001b[39m=\u001b[39;49mdebug,\n\u001b[0;32m   1969\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   1970\u001b[0m ):\n\u001b[0;32m   1971\u001b[0m     \u001b[39mif\u001b[39;49;00m stream_mode \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mvalues\u001b[39;49m\u001b[39m\"\u001b[39;49m:\n\u001b[0;32m   1972\u001b[0m         latest \u001b[39m=\u001b[39;49m chunk\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[39m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m     \u001b[39m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m     \u001b[39m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m     \u001b[39m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[39m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[39mwhile\u001b[39;00m loop\u001b[39m.\u001b[39mtick(input_keys\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_channels):\n\u001b[1;32m-> 1670\u001b[0m         \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m runner\u001b[39m.\u001b[39;49mtick(\n\u001b[0;32m   1671\u001b[0m             loop\u001b[39m.\u001b[39;49mtasks\u001b[39m.\u001b[39;49mvalues(),\n\u001b[0;32m   1672\u001b[0m             timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_timeout,\n\u001b[0;32m   1673\u001b[0m             retry_policy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretry_policy,\n\u001b[0;32m   1674\u001b[0m             get_waiter\u001b[39m=\u001b[39;49mget_waiter,\n\u001b[0;32m   1675\u001b[0m         ):\n\u001b[0;32m   1676\u001b[0m             \u001b[39m# emit output\u001b[39;49;00m\n\u001b[0;32m   1677\u001b[0m             \u001b[39myield from\u001b[39;49;00m output()\n\u001b[0;32m   1678\u001b[0m \u001b[39m# emit output\u001b[39;00m\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\pregel\\runner.py:231\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    229\u001b[0m t \u001b[39m=\u001b[39m tasks[\u001b[39m0\u001b[39m]\n\u001b[0;32m    230\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m     run_with_retry(\n\u001b[0;32m    232\u001b[0m         t,\n\u001b[0;32m    233\u001b[0m         retry_policy,\n\u001b[0;32m    234\u001b[0m         configurable\u001b[39m=\u001b[39;49m{\n\u001b[0;32m    235\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[0;32m    236\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[0;32m    237\u001b[0m         },\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommit(t, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    240\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[39m.\u001b[39mwrites\u001b[39m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[39m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m task\u001b[39m.\u001b[39;49mproc\u001b[39m.\u001b[39;49minvoke(task\u001b[39m.\u001b[39;49minput, config)\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m ParentCommand \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:464\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    463\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m, config)\n\u001b[0;32m    465\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     context\u001b[39m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 226\u001b[0m     ret \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, Runnable) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurse:\n\u001b[0;32m    228\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\graph\\graph.py:96\u001b[0m, in \u001b[0;36mBranch._route\u001b[1;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[0;32m     94\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m     95\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minvoke(value, config)\n\u001b[1;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_finish(writer, \u001b[39minput\u001b[39;49m, result, config)\n",
      "File \u001b[1;32md:\\ExtraAcads\\DS & AI\\github\\serene-solace-sakha\\sakha-env\\Lib\\site-packages\\langgraph\\graph\\graph.py:132\u001b[0m, in \u001b[0;36mBranch._finish\u001b[1;34m(self, writer, input, result, config)\u001b[0m\n\u001b[0;32m    129\u001b[0m     result \u001b[39m=\u001b[39m [result]\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mends:\n\u001b[0;32m    131\u001b[0m     destinations: Sequence[Union[Send, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 132\u001b[0m         r \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(r, Send) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mends[r] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m result\n\u001b[0;32m    133\u001b[0m     ]\n\u001b[0;32m    134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     destinations \u001b[39m=\u001b[39m cast(Sequence[Union[Send, \u001b[39mstr\u001b[39m]], result)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tools'",
      "\u001b[0mDuring task with name 'Frienn' and id 'bb012726-4c78-0822-eb1d-a150dca39f49'"
     ]
    }
   ],
   "source": [
    "user_input = \"ok\"\n",
    "config = {\"configurable\": {\"thread_id\": 121, \"user_id\": 'user_id'}}\n",
    "conversation_graph.invoke({\"user_input\": user_input}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sakha-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe92ede66fbacaed253741073118c00559929976131b08e482b9b1b80c47130c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
